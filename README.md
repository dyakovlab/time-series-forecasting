### Project Documentation: Time Series Forecasting with Prophet, LSTM, and XGBoost

---

#### **Project Overview**
This project focuses on forecasting future values based on time series data. Three different machine learning models—**Prophet**, **LSTM**, and **XGBoost**—are implemented to predict sales for a given product. The project includes data preprocessing, model training, evaluation, and an interactive dashboard for result visualization.

---

#### **Dataset**
The dataset consists of historical sales data, including the following features:
- **Date (`ds`)**: The date of the transaction.
- **Quantity Sold (`y`)**: The quantity sold on a given date.
- **Additional Features**:
  - Lags of previous sales (used for XGBoost).
  - Day of the week and month indicators.

The dataset was split into training and testing sets (80% training, 20% testing) for model evaluation.

---

#### **Models Used**

##### **1. Prophet**
- **Purpose**: Designed for time series data with strong seasonal patterns and trends.
- **Key Features**:
  - Automatic detection of yearly, weekly, and daily seasonality.
  - Supports holiday effects.
- **Implementation**:
  - The model was trained on the historical data and used to forecast future sales.
  - Forecast results were visualized to show the trend and seasonal components.

##### **2. LSTM (Long Short-Term Memory)**
- **Purpose**: A type of recurrent neural network (RNN) capable of learning long-term dependencies in sequential data.
- **Key Features**:
  - Captures temporal dependencies in the data.
  - Handles complex time series patterns.
- **Implementation**:
  - The model was trained using sequences of past sales values to predict future sales.
  - The input data was normalized, and the model output was inverse-transformed for interpretation.
  - An autoregressive approach was used for future predictions.

##### **3. XGBoost**
- **Purpose**: A gradient boosting framework optimized for speed and performance.
- **Key Features**:
  - Supports custom features like lags and rolling averages.
  - Handles missing values and provides feature importance.
- **Implementation**:
  - The model was trained on engineered features, including lagged sales data.
  - Future predictions were generated by updating lag features iteratively.

---

#### **Evaluation Metrics**
The models were evaluated using the following metrics:
- **Mean Absolute Error (MAE)**: Measures the average magnitude of errors in predictions.
- **Root Mean Squared Error (RMSE)**: Emphasizes larger errors due to squaring.
- **Mean Absolute Percentage Error (MAPE)**: Expresses prediction accuracy as a percentage.

These metrics provided insights into the performance of each model.

---

#### **Interactive Dashboard**
An interactive dashboard was developed using **Streamlit**. The dashboard allows users to:
- Visualize true values and predictions for each model.
- Compare model metrics.
- Generate future predictions interactively by selecting the number of days to forecast.

##### **Dashboard Features**:
- **Model Comparison**: Users can view graphs of true sales values against model predictions.
- **Future Predictions**: The dashboard supports interactive future forecasting using Prophet, LSTM, and XGBoost.

---

#### **Project Structure**

```
time-series-forecasting/
│
├── data/
│   ├── raw/                            # Raw datasets
│   ├── processed/                      # Processed datasets and features
│   └── forecast/                       # Forecast results (e.g., Prophet predictions)
│
├── models/                             # Saved models (LSTM, XGBoost, Prophet)
│
├── src/                                # Source code
│   ├── data_preprocessing.py           # Data preprocessing scripts
│   ├── test_data_preprocessing.py      # Test data preprocessing scripts
│   ├── prophet_model.py                # Prophet model implementation
│   ├── lstm_model.py                   # LSTM model implementation
│   ├── xgboost_model.py                # XGBoost model implementation
│   ├── compare_models.py               # Model evaluation and comparison
│
├── dashboard/                          # Streamlit dashboard
│   └── dashboard.py                    # Dashboard script
│
├── README.md                           # Project documentation
└── requirements.txt                    # Python dependencies
```

---

#### **How to Run the Project**

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/dyakovlab/time-series-forecasting.git
   cd time-series-forecasting
   ```

2. **Install Dependencies**:
   Create a virtual environment and install the required packages:
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate 
   pip install -r requirements.txt
   ```

3. **Run Data Preprocessing**:
   Prepare the data for model training and evaluation:
   ```bash
   python src/data_preprocessing.py
   ```

4. **Train Models**:
   Train each model by running the corresponding scripts:
   ```bash
   python src/prophet_model.py
   python src/lstm_model.py
   python src/xgboost_model.py
   ```

5. **Compare Models**:
   Evaluate and compare model performance:
   ```bash
   python src/compare_models.py
   ```

6. **Launch the Dashboard**:
   Run the interactive Streamlit dashboard:
   ```bash
   streamlit run dashboard/dashboard.py
   ```

---

#### **Dependencies**
The project requires the following Python libraries:
- **Pandas**: For data manipulation.
- **Numpy**: For numerical computations.
- **Matplotlib**: For visualization.
- **Streamlit**: For the interactive dashboard.
- **TensorFlow**: For the LSTM model.
- **XGBoost**: For the gradient boosting model.
- **Prophet**: For time series forecasting.
- **Scikit-learn**: For metrics and preprocessing.
